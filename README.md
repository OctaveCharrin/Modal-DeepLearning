# Modal-DeepLearning

Deep neural networks have gained popularity in various fields due to their reliability in image classification tasks. However, training these networks typically demands a substantial amount of labeled data. Consequently, significant preprocessing of datasets is required to ensure a properly labeled dataset for supervised learning. An alternative approach to mitigate the costly dataset preparation effort is to label only a small portion of the dataset and train the model using both labeled and unlabeled images, which are often abundant and readily available. This learning paradigm, known as semi-supervised learning, will be investigated as part of the Kaglle competition ”INF473V 2023 Challenge”.

## Description

This project was conducted as part of the class INF473V which consisted of two Kaggle competitions ([INF473V 2023 Challenge](https://www.kaggle.com/competitions/inf473v-2023-challenge) and [INF473V 2023 Challenge V2](https://www.kaggle.com/competitions/inf473v-2023-challenge-v2)).

Datasets can be found on respective Kaggle pages.

## Report

The final report containing the theory behind the code can be found in the file `INF473V - REPORT - CharrinOctave - YaiciInes.pdf`.
